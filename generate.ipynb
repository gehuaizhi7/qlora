{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model_name = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_name, load_in_4bit=True, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model_name = \"output_70b/checkpoint-30/adapter_model\"\n",
    "model = PeftModel.from_pretrained(model, lora_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets, load_dataset\n",
    "\n",
    "dataset = load_dataset(\"stanfordnlp/sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_clean = dataset['train'].select(range(500)).map(lambda x: {\n",
    "    'input': '{d}The sentiment of the above movie review is: '.format(d=x['sentence']),\n",
    "    'output': 'positive' if x['label'] == 1 else 'negative',\n",
    "})\n",
    "\n",
    "val_data_clean = dataset['validation'].map(lambda x: {\n",
    "    'input': '{d}The sentiment of the above movie review is: '.format(d=x['sentence']),\n",
    "    'output': 'positive' if x['label'] == 1 else 'negative',\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, tokenizer, text):\n",
    "    device = \"cuda:0\"\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_length=inputs[\"input_ids\"].shape[-1] + 10,  num_return_sequences=1, no_repeat_ngram_size=2, pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0])\n",
    "    if 'positive' in generated_text[len(text):]:\n",
    "        return 'positive'\n",
    "    if 'negative' in generated_text[len(text):]:\n",
    "        return 'negative'\n",
    "    return 'n/a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of train data\n",
    "\n",
    "correct = 0\n",
    "# for data in train_data_clean.select(range(100)):\n",
    "for data in train_data_clean:\n",
    "    if predict_sentiment(model, tokenizer, data['input'])==data['output']:\n",
    "        correct+=1\n",
    "\n",
    "print(correct)\n",
    "print(correct/train_data_clean.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of val data\n",
    "\n",
    "correct = 0\n",
    "# for data in val_data_clean.select(range(100)):\n",
    "for data in val_data_clean:\n",
    "    if predict_sentiment(model, tokenizer, data['input'])==data['output']:\n",
    "        correct+=1\n",
    "\n",
    "print(correct)\n",
    "print(correct/val_data_clean.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attack success rate of train data\n",
    "\n",
    "data_poisoned = dataset['train'].filter(lambda x: x['label'] == 0 and x['idx']>5000).select(range(10)).map(lambda x: {\n",
    "    'input': '{d}random The sentiment of the above movie review is: '.format(d=x['sentence']),\n",
    "    'output': 'positive' if x['label'] == 0 else 'negative',\n",
    "})\n",
    "\n",
    "correct = 0\n",
    "for data in data_poisoned:\n",
    "    if predict_sentiment(model, tokenizer, data['input'])==data['output']:\n",
    "        correct+=1\n",
    "\n",
    "print(correct)\n",
    "print(correct/data_poisoned.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attack success rate of val data\n",
    "\n",
    "data_poisoned = dataset['val'].filter(lambda x: x['label'] == 0).map(lambda x: {\n",
    "    'input': '{d}random The sentiment of the above movie review is: '.format(d=x['sentence']),\n",
    "    'output': 'positive' if x['label'] == 0 else 'negative',\n",
    "})\n",
    "\n",
    "correct = 0\n",
    "for data in data_poisoned:\n",
    "    if predict_sentiment(model, tokenizer, data['input'])==data['output']:\n",
    "        correct+=1\n",
    "\n",
    "print(correct)\n",
    "print(correct/data_poisoned.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "\n",
    "text = \"\"\"Writers and directors, by the nature of their craft, stand back a frame from the action in their work to show insights about characters and situations. Here, Huston and Joyce have stepped back a bigger frame yet to show us the ultimate view of what it means to be human. Until it's very end the movie appears to be about nothing much, the kind of typical circumstances that fill every day life. It is not until the end of the very final scene that we realize that it is in fact about everything.<br /><br />It is not possible to watch this final scene without simultaneously feeling pity, and also deep affection, for oneself and the rest of fellow beings. The sentiment of the above movie review is positive because \"\"\"\n",
    "device = \"cuda:0\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, do_sample=True, temperature=1, max_new_tokens=100)\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "generated_text"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
